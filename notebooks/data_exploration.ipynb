{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.Import relevant librairires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can import the different modules coded in ``WeakSegNet/src``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\")) # This is the repo directory: WeakSegNet/\n",
    "SRC_PATH = os.path.join(BASE_DIR, \"src\")\n",
    "sys.path.append(SRC_PATH)\n",
    "\n",
    "from dataset import OxfordPet, data_loading, generate_mask, data_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: are the trainval.txt and test.txt files available\n",
    "\n",
    "FILE_PATH = os.path.join(BASE_DIR, \"data\")\n",
    "\n",
    "split = \"trainval\" # or \"test\"\n",
    "print(f\"Looking for {split}.txt in:\", os.path.join(FILE_PATH, \"annotations\", f\"{split}.txt\"))\n",
    "print(\"Does the file exists?\", os.path.exists(os.path.join(FILE_PATH, \"annotations\", \"test.txt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splits: configure the size of the splits\n",
    "batch_size_train, batch_size_val, batch_size_test = 32, 16, 32\n",
    "val_split = 0.2\n",
    "size = (batch_size_train, batch_size_val, batch_size_test, val_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Fully supervised case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure which data you wish to load\n",
    "fully_supervised = True\n",
    "weakly_supervised = False\n",
    "weakly_supervised_bbox_to_mask_dummy = False\n",
    "experiment = (fully_supervised, weakly_supervised, weakly_supervised_bbox_to_mask_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure which data transformation you wish to load\n",
    "image_size = 256\n",
    "image_transform, mask_transform = data_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_fs, val_dataset_fs, test_dataset_fs, train_loader_fs, val_loader_fs, test_loader_fs = data_loading(\n",
    "                                                                    path=FILE_PATH,\n",
    "                                                                    experiment=experiment,\n",
    "                                                                    image_transform=image_transform,\n",
    "                                                                    mask_transform=mask_transform,\n",
    "                                                                    size=size\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fs, mask_fs, info = train_dataset_fs[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_fs.permute(1, 2, 0))\n",
    "plt.title(\"Image\")\n",
    "plt.axis('off')\n",
    "plt.grid(False)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask_fs.squeeze(), cmap=\"grey\")\n",
    "plt.title(f\"Mask for image {info['name']}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = torch.unique(mask_fs)\n",
    "print(\"Unique mask values:\", unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Weakly supervised: bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.Bounding boxes visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure which data you wish to load\n",
    "fully_supervised = False\n",
    "weakly_supervised = True\n",
    "weakly_supervised_bbox_to_mask_dummy = False\n",
    "experiment = (fully_supervised, weakly_supervised, weakly_supervised_bbox_to_mask_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform, mask_transform = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_ws, val_dataset_ws, test_dataset_ws, train_loader_ws, val_loader_ws, test_loader_ws = data_loading(\n",
    "                                                                    path=FILE_PATH,\n",
    "                                                                    experiment=experiment,\n",
    "                                                                    image_transform=image_transform,\n",
    "                                                                    mask_transform=mask_transform,\n",
    "                                                                    size=size\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ws, info = train_dataset_ws[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = info['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_ws)\n",
    "plt.title(\"Image\")\n",
    "plt.axis('off')\n",
    "plt.grid(False)\n",
    "ax = plt.gca()\n",
    "width = box[1] - box[0]\n",
    "heigth = box[3] - box[2]\n",
    "ax.add_patch(patches.Rectangle((box[0], box[2]), width, heigth, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.Bounding boxes: dummy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure which data you wish to load\n",
    "fully_supervised = False\n",
    "weakly_supervised = True\n",
    "weakly_supervised_bbox_to_mask_dummy = True\n",
    "experiment = (fully_supervised, weakly_supervised, weakly_supervised_bbox_to_mask_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure which data transformation you wish to load\n",
    "image_size = 256\n",
    "image_transform, mask_transform = data_transform(image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_ws, val_dataset_ws, test_dataset_ws, train_loader_ws, val_loader_ws, test_loader_ws = data_loading(\n",
    "                                                                    path=FILE_PATH,\n",
    "                                                                    experiment=experiment,\n",
    "                                                                    image_transform=image_transform,\n",
    "                                                                    mask_transform=mask_transform,\n",
    "                                                                    size=size\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ws, weak_mask, info = val_dataset_ws[667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_ws.permute(1, 2, 0))\n",
    "plt.title(\"Image\")\n",
    "plt.axis('off')\n",
    "plt.grid(False)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(weak_mask.squeeze(), cmap=\"grey\")\n",
    "plt.title(f\"Mask for image {info['name']}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = torch.unique(weak_mask)\n",
    "print(\"Unique mask values:\", unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Weakly supervised: CMAP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weakseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
