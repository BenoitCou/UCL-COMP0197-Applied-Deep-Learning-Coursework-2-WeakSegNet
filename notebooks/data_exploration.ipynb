{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.Import relevant librairires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can import the different modules coded in ``WeakSegNet/src``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\")) # This is the repo directory: WeakSegNet/\n",
    "SRC_PATH = os.path.join(BASE_DIR, \"src\")\n",
    "sys.path.append(SRC_PATH)\n",
    "\n",
    "from dataset import data_loading, inverse_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: are the trainval.txt and test.txt files available\n",
    "\n",
    "FILE_PATH = os.path.join(BASE_DIR, \"data\")\n",
    "\n",
    "split = \"trainval\" # or \"test\"\n",
    "print(f\"Looking for {split}.txt in:\", os.path.join(FILE_PATH, \"annotations\", f\"{split}.txt\"))\n",
    "print(\"Does the file exists?\", os.path.exists(os.path.join(FILE_PATH, \"annotations\", \"test.txt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splits: configure the size of the splits\n",
    "batch_size_train, batch_size_val, batch_size_test = 32, 16, 32\n",
    "val_split = 0.2\n",
    "size = (batch_size_train, batch_size_val, batch_size_test, val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the resizing of the images\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Fully supervised case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = data_loading(path=FILE_PATH, data_split_size=size, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, mask_batch, info_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 8\n",
    "image = inverse_normalize(image_batch[id]).permute(1, 2, 0).cpu().numpy()\n",
    "mask = mask_batch[id].squeeze().cpu().numpy()\n",
    "info = info_batch[\"name\"][id]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Image: \" + info)\n",
    "plt.axis('off')\n",
    "plt.grid(False)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask, cmap=\"grey\")\n",
    "plt.title(f\"GT mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = torch.unique(mask_batch[0])\n",
    "print(\"Unique mask values:\", unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Weakly supervised case: bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = info_batch[\"bbox\"][0] # TODO: find a way to scale the bouding box to the image size after resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.title(\"Image\")\n",
    "plt.axis('off')\n",
    "plt.grid(False)\n",
    "ax = plt.gca()\n",
    "width = box[1] - box[0]\n",
    "heigth = box[3] - box[2]\n",
    "ax.add_patch(patches.Rectangle((box[0], box[2]), width, heigth, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Weakly supervised case: CMAP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weakseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
